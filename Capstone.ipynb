{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Header"
    ]
   },
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Prep Test index format: \n",
    "For the purposes of the LSAT, the typical format of \"Prep Test/Section/Question Number as used.  e.g. [21.0,02,05] indicates Prep test 21, Section 2, Question 5.  Two irregularies exist.  First, a decimal was utilized for prep test reference.  This would allow for Prep Test exams to remain both in chronological as well as numerical order since six LSAT prep test exams were released periodically throughout the years.  See here https://www.powerscore.com/lsat/help/pub_ident.cfm.  e.g. \"June 2007\" was imported as [51.5,01,01] since June 2007 falls chronolically between prep test 51 (Dec 2006) and 52 (Sept 2007). \n",
    "\n",
    "Second, section numbers 01 and 02 were utilized consistently throughout the data set since the LSAC consistently provided their exams in LG,LR,LR,RC order throught all of their practice exams online, see https://www.lsac.org/lsat/prep#lsatprepplus .  Since the official LSAT rotates these sections for different students on test day, the section numbers may not correspond with the actual exam a test taker experienced or that is downloaded from a test provider's website such as https://www.kaplan.com . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pipe addition and removal from pipeline\n",
    "Most Python cells within a Jupyter notebook may be run multiple times within the span of running an entire notebook.  However, multiple Spacy pipes labeled the same name may not be re-added/overwritten.  Therefore, several instances of code to delete pipes are commented throught this project.  These instances may be uncommented, run, then commented again to facilitate this process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Code output review:\n",
    "Jupyter notebook as a module titled \"collapsible headings\" which allows code folding based upon Markdown headers.  see here https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/collapsible_headings/readme.html .  While this is not necessary for the production of this notebook, it helps to view the overall continuity of flow since there are a number of code snippets designed to allow the reviewer a glimps into how the data is being processed and returned.  Examples of this non-essential, but helpful code can be found within markdown text titles similar to the following.\n",
    "\n",
    "\"REVIEW sample variable START\" \n",
    "\n",
    "\"REVIEW sample variable END\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T19:12:53.060797Z",
     "start_time": "2020-11-29T19:12:53.044205Z"
    }
   },
   "outputs": [],
   "source": [
    "# Required Packages & other dependencies\n",
    "# NOTE: package imports are duplicated here and throughout the entire project.  This will facilitate\n",
    "#   (1) Ease of import: One only needs to look here to view every required installation\n",
    "#   (2) Understanding of functionality: duplicated package imports are commented out, but should identify \n",
    "#         to the reader where imports become necessary\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import numpy as np \n",
    "\n",
    "from spacy.util import minibatch, compounding, decaying\n",
    "\n",
    "import itertools\n",
    "from functools import reduce\n",
    "import operator\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: A Spacy model must either be loaded from a default model or a custom designed.  \n",
    "#    For this capstone, \"en_core_web_sm\" was used.  More information may be found here\n",
    "#    https://spacy.io/usage/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T21:37:32.884668Z",
     "start_time": "2020-12-09T21:37:29.708889Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "df = pd.read_csv('PT1988.v4.txt', sep='\\t', encoding='utf_8') # allows for special utf8 char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T21:37:33.070205Z",
     "start_time": "2020-12-09T21:37:32.890585Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Adds the correct answer (as str) to the df labeled \"Correct_Strings\".\n",
    "# NOTE: this cell was NOT USED in this capstone and may be omitted.\n",
    "\n",
    "Correct_Strings = []     # A list of [str, str] containing the correct answers\n",
    "for row in range(len(df)):    \n",
    "    Correct_Letter_Col = df.loc[row, \"Correct_Letter\"]        # List of [str, str] of correct letters. [A, C, D, A,...]\n",
    "    Correct_Strings.append(df.loc[row, Correct_Letter_Col])   # appends the str of correct answers to Correct_strings as text\n",
    "   \n",
    "df['Correct_Strings'] = Correct_Strings   # adds the list of correct answers to df as a column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out and correcting Sentence Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T21:37:38.591681Z",
     "start_time": "2020-12-09T21:37:33.078017Z"
    },
    "init_cell": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# relevant review material\n",
    "# Custom Sentence stops, for \":\"   https://spacy.io/usage/linguistic-features#sbd-custom\n",
    "# Tokens, including \"nbor()\", and \"is_sent_start\" : https://spacy.io/api/token\n",
    "# Rule based matching: https://spacy.io/usage/rule-based-matching\n",
    "# Online Spacy Pattern Matcher : https://explosion.ai/demos/matcher\n",
    "\n",
    "# import spacy  # Import Spacy module\n",
    "# Dissables non-essentiaal pipes such as NER, tagger, etc.  https://spacy.io/usage/processing-pipelines#disabling\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"ner\"])\n",
    "\n",
    "# Custom boundary markers for sentences updated below.  Where possible, a small sample of text with \"\\n\" is used\n",
    "#    to illustrate the originl issue.  \n",
    "# NOTE: a 'doc' object is a single stimulus of multiple sentences in the function.\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == \":\":  #  See 28.0_02_07 as example, \"Tiya: But\\nsome...\"\n",
    "            doc[token.i+2].is_sent_start = False \n",
    "        if token.text == \":\":  \n",
    "            doc[token.i+1].is_sent_start = False\n",
    "        if token.text == \":\":  #changes here....   28.0_02_07, 34.0_02_08 example\n",
    "            doc[token.i].is_sent_start = False \n",
    "        if token.text == '.' and token.nbor().text == '\"':  #changes here.  See \"20.0_02_22\" as example  .\"\\n\n",
    "            doc[token.i+1].is_sent_start = False\n",
    "        if token.text == '?' and token.nbor().text == '\"':  #changes here.  See \"22.0_02_11\" as example  ?\"\\n\n",
    "            doc[token.i+1].is_sent_start = False  \n",
    "        if token.text == '!' and token.nbor().text == '\"':  #changes here.  \n",
    "            doc[token.i+1].is_sent_start = False\n",
    "        if token.text == ',' and token.nbor().text == '\"':  #changes here.  See \"31.0_02_15\" as example\n",
    "            doc[token.i].is_sent_start = False\n",
    "        if token.text == 'Dr.':  \n",
    "            doc[token.i+1].is_sent_start = False\n",
    "        if token.text == ':' and token.nbor().text == ' ':  #changes here.  See \"24.0_02_15\" as example \"Dr. Z: \\nMany\"\n",
    "            doc[token.i+2].is_sent_start = False\n",
    "        if token.text == ':' and token.nbor().text == ' ':  #changes here.  See \"\" as example \"Dr. Z: \\nMany\"\n",
    "            doc[token.i+1].is_sent_start = False                \n",
    "    return doc\n",
    "\n",
    "\n",
    "# adds this sentence boundary recognizer before the parser. \n",
    "nlp.add_pipe(set_custom_boundaries, before=\"parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T21:37:38.591681Z",
     "start_time": "2020-12-09T21:37:33.078017Z"
    },
    "init_cell": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# To delete this pipeline part\n",
    "# name, component = nlp.remove_pipe(\"set_custom_boundaries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REVIEW Sent Tokenizer Test START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T19:07:53.981247Z",
     "start_time": "2020-11-29T19:07:53.751316Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sam: In a recent survey, over 95 percent of people who purchased a Starlight automobile last year said they were highly satisfied with their purchase. Since people who have purchased a new car in the last year are not highly satisfied if that car has a manufacturing defect, Starlight automobiles are remarkably free from such defects.  Tiya: But some manufacturing defects in automobiles become apparent only after several years of use.\n",
      "word:\t Sent_Start\tNeighbor0\n",
      "Sam \t True \t\t :\n",
      ": \t False \t\t In\n",
      "In \t False \t\t a\n",
      "a \t False \t\t recent\n",
      "recent \t None \t\t survey\n",
      "survey \t None \t\t ,\n",
      ", \t None \t\t over\n",
      "over \t None \t\t 95\n",
      "95 \t None \t\t percent\n",
      "percent \t None \t\t of\n",
      "of \t None \t\t people\n",
      "people \t None \t\t who\n",
      "who \t None \t\t purchased\n",
      "purchased \t None \t\t a\n",
      "a \t None \t\t Starlight\n",
      "Starlight \t None \t\t automobile\n",
      "automobile \t None \t\t last\n",
      "last \t None \t\t year\n",
      "year \t None \t\t said\n",
      "said \t None \t\t they\n",
      "they \t None \t\t were\n",
      "were \t None \t\t highly\n",
      "highly \t None \t\t satisfied\n",
      "satisfied \t None \t\t with\n",
      "with \t None \t\t their\n",
      "their \t None \t\t purchase\n",
      "purchase \t None \t\t .\n",
      ". \t None \t\t Since\n",
      "Since \t True \t\t people\n",
      "people \t None \t\t who\n",
      "who \t None \t\t have\n",
      "have \t None \t\t purchased\n",
      "purchased \t None \t\t a\n",
      "a \t None \t\t new\n",
      "new \t None \t\t car\n",
      "car \t None \t\t in\n",
      "in \t None \t\t the\n",
      "the \t None \t\t last\n",
      "last \t None \t\t year\n",
      "year \t None \t\t are\n",
      "are \t None \t\t not\n",
      "not \t None \t\t highly\n",
      "highly \t None \t\t satisfied\n",
      "satisfied \t None \t\t if\n",
      "if \t None \t\t that\n",
      "that \t None \t\t car\n",
      "car \t None \t\t has\n",
      "has \t None \t\t a\n",
      "a \t None \t\t manufacturing\n",
      "manufacturing \t None \t\t defect\n",
      "defect \t None \t\t ,\n",
      ", \t None \t\t Starlight\n",
      "Starlight \t None \t\t automobiles\n",
      "automobiles \t None \t\t are\n",
      "are \t None \t\t remarkably\n",
      "remarkably \t None \t\t free\n",
      "free \t None \t\t from\n",
      "from \t None \t\t such\n",
      "such \t None \t\t defects\n",
      "defects \t None \t\t .\n",
      ". \t None \t\t  \n",
      "  \t None \t\t Tiya\n",
      "Tiya \t True \t\t :\n",
      ": \t False \t\t But\n",
      "But \t False \t\t some\n",
      "some \t False \t\t manufacturing\n",
      "manufacturing \t None \t\t defects\n",
      "defects \t None \t\t in\n",
      "in \t None \t\t automobiles\n",
      "automobiles \t None \t\t become\n",
      "become \t None \t\t apparent\n",
      "apparent \t None \t\t only\n",
      "only \t None \t\t after\n",
      "after \t None \t\t several\n",
      "several \t None \t\t years\n",
      "years \t None \t\t of\n",
      "of \t None \t\t use\n",
      "use \t None \t\t .\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "[E042] Error accessing doc[78].nbor(1), for doc of length 79.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a67f2606e7b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word:\\t Sent_Start\\tNeighbor0\"\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# column headers used in \"for\" loop below\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_stimulus_to_sentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sent_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\t\\t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnbor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mtoken.pyx\u001b[0m in \u001b[0;36mspacy.tokens.token.Token.nbor\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: [E042] Error accessing doc[78].nbor(1), for doc of length 79."
     ]
    }
   ],
   "source": [
    "# Word Tokens and Neighbors\n",
    "#\n",
    "# This review snippet was utilized in two ways.\n",
    "#   First: to identify whether or not a token was or was not recognized as a sentence start.\n",
    "#   Second: to help identify neighbors to certian word tokens used to identify and fix incorrect sentence boundaries\n",
    "#     by utilizing \"w.nbor()\" (i.e. the word's neighbor) in the \"if\" statements of the sentence set_custom_boundaries.\n",
    "\n",
    "test_boundaries = \"28.0_02_07\"  # Sample PT/Sec/Num of the stimulus to review\n",
    "test_stimulus_to_sentences = nlp([*df[df['Order'].str.contains(test_boundaries)].loc[df[df['Order']==test_boundaries].index.values,\"Stimulus\"]][0]).text\n",
    "# doc_test_sentences = nlp(test_stimulus_to_sentences)\n",
    "print(test_stimulus_to_sentences)  # print's the entire stimulus as a single line.\n",
    "\n",
    "print(\"word:\\t Sent_Start\\tNeighbor(0) to the right\")  # column headers used in \"for\" loop below\n",
    "for w in nlp(test_stimulus_to_sentences):\n",
    "    print(w, \"\\t\", w.is_sent_start, \"\\t\\t\", w.nbor())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T19:09:21.937766Z",
     "start_time": "2020-11-29T19:09:21.890911Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Sam: In a recent survey, over 95 percent of people who purchased a Starlight automobile last year said they were highly satisfied with their purchase.\n",
      "1 Since people who have purchased a new car in the last year are not highly satisfied if that car has a manufacturing defect, Starlight automobiles are remarkably free from such defects.  \n",
      "2 Tiya: But some manufacturing defects in automobiles become apparent only after several years of use.\n"
     ]
    }
   ],
   "source": [
    "# Print a test Stimulus to Sentences to evaluate the tokenizer\n",
    "#\n",
    "# Used to evaluate a single stimulus and verify that sentences were properly parsed.\n",
    "# nlp.replace_pipe(\"set_custom_boundaries\", )\n",
    "test_boundaries = \"28.0_02_07\"   # <- enter the \"PT_Sec_Quest\" to evaluate\n",
    "\n",
    "# NOTE: 106 is the absolute row index for 28.0_02_07 above.  However, this code only requires that the \"28.0_02_07\" format \n",
    "#    be used\n",
    "# logic behind stimulus call     [*df[df['Order'].str.contains(\"19.0_01_07\")]   .loc[106,                                          \"docS\"        ] .sents]   \n",
    "test_stimulus_to_sentences = nlp([*df[df['Order'].str.contains(test_boundaries)].loc[df[df['Order']==test_boundaries].index.values,\"Stimulus\"]][0]).sents\n",
    " \n",
    "ii = 0\n",
    "for s in test_stimulus_to_sentences:\n",
    "    print(ii, s)\n",
    "    ii = ii + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REVIEW Sent Tokenizer Test END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T18:04:40.418955Z",
     "start_time": "2020-11-29T18:04:40.406275Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['set_custom_boundaries', 'parser']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Prints the current pipe order in the Spacy pipeline\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T21:38:15.559468Z",
     "start_time": "2020-12-09T21:37:38.594615Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Attaches a list of 'doc' objects for each sentence for each stimuli\n",
    "#   Code modified from: https://stackoverflow.com/questions/46981137/tokenizing-using-pandas-and-spacy\n",
    "df['docS'] = df['Stimulus'].apply(lambda x: nlp(x)) # creates a col of nlp docs from the Stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T21:38:15.559468Z",
     "start_time": "2020-12-09T21:37:38.594615Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Order</th>\n",
       "      <th>PT</th>\n",
       "      <th>Section</th>\n",
       "      <th>Question_Number</th>\n",
       "      <th>Stimulus</th>\n",
       "      <th>Question_Type</th>\n",
       "      <th>Star_Level</th>\n",
       "      <th>Correct_Letter</th>\n",
       "      <th>Question_Stem</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>END</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Correct_Strings</th>\n",
       "      <th>docS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>51.5_01_01</td>\n",
       "      <td>51.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Economist: Every business strives to increase ...</td>\n",
       "      <td>Main Point</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>Which one of the following most accurately exp...</td>\n",
       "      <td>If an action taken to secure the survival of a...</td>\n",
       "      <td>Some measures taken by a business to increase ...</td>\n",
       "      <td>Only if the employees of a business are also i...</td>\n",
       "      <td>There is no business that does not make effort...</td>\n",
       "      <td>Decreasing the number of employees in a busine...</td>\n",
       "      <td>.</td>\n",
       "      <td>June 2007</td>\n",
       "      <td>Some measures taken by a business to increase ...</td>\n",
       "      <td>(Economist, :, Every, business, strives, to, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>51.5_01_02</td>\n",
       "      <td>51.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>All Labrador retrievers bark a great deal. All...</td>\n",
       "      <td>Parallel Flaw</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>Which one of the following uses flawed reasoni...</td>\n",
       "      <td>All students who study diligently make good gr...</td>\n",
       "      <td>All type A chemicals are extremely toxic to hu...</td>\n",
       "      <td>All students at Hanson School live in Green Co...</td>\n",
       "      <td>All transcriptionists know shorthand. All engi...</td>\n",
       "      <td>All of Kenisha's dresses are very well made. A...</td>\n",
       "      <td>.</td>\n",
       "      <td>June 2007</td>\n",
       "      <td>All type A chemicals are extremely toxic to hu...</td>\n",
       "      <td>(All, Labrador, retrievers, bark, a, great, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>51.5_01_03</td>\n",
       "      <td>51.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>A century in certain ways is like a life, and ...</td>\n",
       "      <td>Inference (Completes)</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>Which one of the following most logically comp...</td>\n",
       "      <td>reminisce about their own lives</td>\n",
       "      <td>fear that their own lives are about to end</td>\n",
       "      <td>focus on what the next century will bring</td>\n",
       "      <td>become very interested in the history of the c...</td>\n",
       "      <td>reflect on how certain unfortunate events of t...</td>\n",
       "      <td>.</td>\n",
       "      <td>June 2007</td>\n",
       "      <td>become very interested in the history of the c...</td>\n",
       "      <td>(A, century, in, certain, ways, is, like, a, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       Order    PT  Section  Question_Number  \\\n",
       "0      0  51.5_01_01  51.5        1                1   \n",
       "1      1  51.5_01_02  51.5        1                2   \n",
       "2      2  51.5_01_03  51.5        1                3   \n",
       "\n",
       "                                            Stimulus          Question_Type  \\\n",
       "0  Economist: Every business strives to increase ...             Main Point   \n",
       "1  All Labrador retrievers bark a great deal. All...          Parallel Flaw   \n",
       "2  A century in certain ways is like a life, and ...  Inference (Completes)   \n",
       "\n",
       "   Star_Level Correct_Letter  \\\n",
       "0           1              B   \n",
       "1           1              B   \n",
       "2           1              D   \n",
       "\n",
       "                                       Question_Stem  \\\n",
       "0  Which one of the following most accurately exp...   \n",
       "1  Which one of the following uses flawed reasoni...   \n",
       "2  Which one of the following most logically comp...   \n",
       "\n",
       "                                                   A  \\\n",
       "0  If an action taken to secure the survival of a...   \n",
       "1  All students who study diligently make good gr...   \n",
       "2                    reminisce about their own lives   \n",
       "\n",
       "                                                   B  \\\n",
       "0  Some measures taken by a business to increase ...   \n",
       "1  All type A chemicals are extremely toxic to hu...   \n",
       "2         fear that their own lives are about to end   \n",
       "\n",
       "                                                   C  \\\n",
       "0  Only if the employees of a business are also i...   \n",
       "1  All students at Hanson School live in Green Co...   \n",
       "2          focus on what the next century will bring   \n",
       "\n",
       "                                                   D  \\\n",
       "0  There is no business that does not make effort...   \n",
       "1  All transcriptionists know shorthand. All engi...   \n",
       "2  become very interested in the history of the c...   \n",
       "\n",
       "                                                   E END      Notes  \\\n",
       "0  Decreasing the number of employees in a busine...   .  June 2007   \n",
       "1  All of Kenisha's dresses are very well made. A...   .  June 2007   \n",
       "2  reflect on how certain unfortunate events of t...   .  June 2007   \n",
       "\n",
       "                                     Correct_Strings  \\\n",
       "0  Some measures taken by a business to increase ...   \n",
       "1  All type A chemicals are extremely toxic to hu...   \n",
       "2  become very interested in the history of the c...   \n",
       "\n",
       "                                                docS  \n",
       "0  (Economist, :, Every, business, strives, to, i...  \n",
       "1  (All, Labrador, retrievers, bark, a, great, de...  \n",
       "2  (A, century, in, certain, ways, is, like, a, l...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)  # Run time 30 seconds on 3606 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "tags": [
     "Header"
    ]
   },
   "source": [
    "# Create Search Patterns for identifying Conclusions based upon classic keywords (not utilized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: This was an initial base case model for the capstone. Later, it was abandonded for a base case that more closely modeled the original intent of this project.  It has been left here for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T18:02:17.489560Z",
     "start_time": "2020-11-28T18:01:56.089Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Resources for basic Spacy keyword search patterns are below.\n",
    "# \n",
    "# https://stackabuse.com/python-for-nlp-vocabulary-and-phrase-matching-with-spacy/\n",
    "# Interactive Pattern Matcher online : https://explosion.ai/demos/matcher\n",
    "# import spacy\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Conclusion 1: by Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T18:02:17.493464Z",
     "start_time": "2020-11-28T18:01:57.207Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c1 = [{'LOWER': 'thus'}]        # Thus\n",
    "c2 = [{'LOWER': 'therefore'}]   # Therefore\n",
    "c3 = [{'LOWER': 'hence'}]       # Hence\n",
    "c4 = [{'LOWER': 'so'}]          # So\n",
    "c5 = [{'LOWER': 'as'},          # as a result\n",
    "      {'LOWER': 'a'},             \n",
    "      {'LOWER': 'result'}]        \n",
    "c6 = [{'LOWER': 'it'},          # it follows that\n",
    "      {'LOWER': 'follows'},      \n",
    "      {'LOWER': 'that'}]        \n",
    "c7 = [{'LOWER': 'is'},          # is evidence that\n",
    "      {'LOWER': 'evidence'},      \n",
    "      {'LOWER': 'that'}]         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Conclusion 2: by Subsidary Conclusion p171 (selects last conclusion found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# No pattern matching was necessary for this model.  This conclusion type was identified by first finding all instances of keywords from C1 type above, then selecting the last sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Conclusion 3: by Evidence KW p173"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# because, since, ___ is evidence of ___, After all, For\n",
    "# e# represents the evidence keyword number pattern identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T18:02:17.498352Z",
     "start_time": "2020-11-28T18:01:59.062Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "e1 = [{'LOWER': 'because'}]     #   \n",
    "e2 = [{'LOWER': 'since'}]       #\n",
    "e3 = [{'LOWER': 'for'}]         # ***** remove instances e.g. \"are submitted for approval to\"\n",
    "e4 = [{'LOWER': 'is'},          #   \n",
    "      {'LOWER': 'evidence'},    #          \n",
    "      {'LOWER': 'of'}]          #\n",
    "e5 = [{'LOWER': 'after'},       # ***** Assumes that \"After all\" does not start an entire stimulus.\n",
    "      {'LOWER': 'all'}]         #         This pattern match was modified later on to tag the sentence prior to the one found\n",
    "\n",
    "# m_tool.add('CON3b', None, e5)\n",
    "\n",
    "# m_tool.remove(\"CON3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Conclusion 4: from Context p171  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Conclusion 5: as negation of opponents point p171 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The purposes of this capstonme was to identify conclusions based upon this type.  \n",
    "#      It's code is implemented later as an ensemble (CNN,BOW) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Identify Conclusion sentences based upon c1-c3.   (not utilized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T18:02:17.504210Z",
     "start_time": "2020-11-28T18:02:04.905Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cMatches = []\n",
    "c1Matchs = []\n",
    "c2Matchs = []\n",
    "c3aMatchs = []\n",
    "c3bMatchs = []\n",
    "\n",
    "c1_tool = Matcher(nlp.vocab)\n",
    "c3a_tool = Matcher(nlp.vocab)\n",
    "c3b_tool = Matcher(nlp.vocab)\n",
    "\n",
    "c1_tool.add('CON1', None, c1, c2, c3, c4, c5, c6, c7)    # by Conclusion Keyword\n",
    "c3a_tool.add('CON3a', None, e1, e2, e3, e4)\n",
    "c3b_tool.add('CON3b', None, e5)\n",
    "\n",
    "# import numpy as np\n",
    "m = np.empty((0,4))  # A single Matrix per stimulus, Creates an empty Numpy 2D array of SENTENCES x METHOD\n",
    "m2 = []    # An empty list to contain all of the matrices found and add to \"df\"\n",
    "\n",
    "for row in df.loc[:, 'docS']:  # 41 - 48 has some \"after all\"\n",
    "    m = np.empty((0,4))    # Empty's array\n",
    "\n",
    "    for sentence in row.sents:\n",
    "\n",
    "        c1m  = c1_tool(sentence)      # Searches for patterns\n",
    "        c3am = c3a_tool(sentence)\n",
    "        c3bm = c3b_tool(sentence)\n",
    "        \n",
    "        c1mCount  = len(list(c1m))    # \n",
    "        c3amCount = len(list(c3am))\n",
    "        c3bmCount = len(list(c3bm))\n",
    "        \n",
    "        m = np.vstack((m, np.array([c1mCount, 0, c3amCount, c3bmCount])))\n",
    "\n",
    "    \n",
    "    # Wrapup processing of Numpy Matrix\n",
    "    # Fold method 3b into 3a\n",
    "    m[:,2] = list(map(lambda pair: sum(pair), zip(np.roll(m[:,3], 1, axis = 0), m[:,2]))) # After shifting col 3 up one (for \"after all\"), summes method 3b into 3a for 'conclusion by evidence kw'\n",
    "\n",
    "    # if a c1 exhists, finds last non-zero index by method c1 (Conclusion KW) and uses it for c2\n",
    "    if np.any(m[:,0]): m[:,1] = np.bincount([np.max(np.nonzero(m[:,0]))], None, len(m[:,0]))\n",
    "        \n",
    "    # appends numpy matrix to running list, to become a column of counts.\n",
    "    m2.append(m.astype(int))   # appends data found for current stimulus to a master list of all methods found.\n",
    "\n",
    "df['cType_counts'] = m2  # 3-5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T18:02:17.508107Z",
     "start_time": "2020-11-28T18:02:07.121Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# PT/Sec/Quest      QType       [0,1,0]       Sent1\n",
    "#                               [0,1,0]       Sent2\n",
    "#                               [0,1,1]       Sent3\n",
    "#                               [1,1,0]       Sent4\n",
    "dftest = df.loc[:, ['Order', 'Question_Type', 'docS', 'cType_counts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T18:02:17.512031Z",
     "start_time": "2020-11-28T18:02:08.254Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>Question_Type</th>\n",
       "      <th>docS</th>\n",
       "      <th>cType_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.5_01_01</td>\n",
       "      <td>Main Point</td>\n",
       "      <td>(Economist, :, Every, business, strives, to, i...</td>\n",
       "      <td>[[0, 0, 2, 0], [0, 0, 0, 0], [0, 0, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.5_01_02</td>\n",
       "      <td>Parallel Flaw</td>\n",
       "      <td>(All, Labrador, retrievers, bark, a, great, de...</td>\n",
       "      <td>[[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.5_01_03</td>\n",
       "      <td>Inference (Completes)</td>\n",
       "      <td>(A, century, in, certain, ways, is, like, a, l...</td>\n",
       "      <td>[[0, 0, 0, 0], [1, 1, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.5_01_04</td>\n",
       "      <td>Flaw</td>\n",
       "      <td>(Consumer, :, The, latest, Connorly, Report, s...</td>\n",
       "      <td>[[0, 0, 0, 0], [0, 0, 1, 0], [0, 0, 1, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.5_01_05</td>\n",
       "      <td>Weaken</td>\n",
       "      <td>(Scientist, :, Earth, 's, average, annual, tem...</td>\n",
       "      <td>[[0, 0, 0, 0], [0, 0, 0, 0]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Order          Question_Type  \\\n",
       "0  51.5_01_01             Main Point   \n",
       "1  51.5_01_02          Parallel Flaw   \n",
       "2  51.5_01_03  Inference (Completes)   \n",
       "3  51.5_01_04                   Flaw   \n",
       "4  51.5_01_05                 Weaken   \n",
       "\n",
       "                                                docS  \\\n",
       "0  (Economist, :, Every, business, strives, to, i...   \n",
       "1  (All, Labrador, retrievers, bark, a, great, de...   \n",
       "2  (A, century, in, certain, ways, is, like, a, l...   \n",
       "3  (Consumer, :, The, latest, Connorly, Report, s...   \n",
       "4  (Scientist, :, Earth, 's, average, annual, tem...   \n",
       "\n",
       "                                        cType_counts  \n",
       "0         [[0, 0, 2, 0], [0, 0, 0, 0], [0, 0, 0, 0]]  \n",
       "1  [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [1,...  \n",
       "2                       [[0, 0, 0, 0], [1, 1, 0, 0]]  \n",
       "3         [[0, 0, 0, 0], [0, 0, 1, 0], [0, 0, 1, 0]]  \n",
       "4                       [[0, 0, 0, 0], [0, 0, 0, 0]]  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Formats results to save as CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T18:02:17.516906Z",
     "start_time": "2020-11-28T18:02:12.864Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfResults = pd.DataFrame()\n",
    "\n",
    "for index, Order, Question_Type, d, cType_counts in dftest.itertuples():\n",
    "    numS = len(cType_counts)\n",
    "\n",
    "    dfOrder = pd.DataFrame(np.zeros((4,1)).astype(int).astype(str))\n",
    "    dfOrder.iloc[0,0] = Order\n",
    "    \n",
    "    dfQuestion_Type = pd.DataFrame(np.zeros((4,1)).astype(int).astype(str))\n",
    "    dfQuestion_Type.iloc[0,0] = Question_Type    \n",
    "    \n",
    "    dfStim = []\n",
    "    for s in d.sents:\n",
    "        dfStim.append(s.text)\n",
    "\n",
    "    dfTypes = []\n",
    "    for cType_counts in cType_counts:\n",
    "        dfTypes.append(cType_counts.astype(int))\n",
    "\n",
    "    dfQuestion = pd.concat([dfOrder, dfQuestion_Type, pd.DataFrame(np.asarray(dfTypes).astype(int)), pd.DataFrame(dfStim)], axis = 1)\n",
    "    dfResults = pd.concat([dfResults, dfQuestion])\n",
    "\n",
    "    # 25 seconds\n",
    "dfResults.to_csv('output2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ##############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble model to ID conclusions based upon negations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep Train / Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the below list of lists in the format [\"PT_Sec_Quest#\", # of C5 sentence] was used to feed stimuli to the trainer.\n",
    "#    e.g. [[\"19.0_01_07\",  1]] Represents PT19, Section 01, Question 01, where the second sentence \"1\"\n",
    "#       the conclusion as a negation.  A \"-1\" was used to identify stimuli where conclusion as negation was NOT\n",
    "#       present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T21:38:15.632776Z",
     "start_time": "2020-12-09T21:38:15.562410Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "c5train = [[\"19.0_01_07\",  1],  \n",
    "           [\"20.0_01_14\",  2], \n",
    "           [\"20.0_02_22\",  3],\n",
    "           [\"23.0_01_02\",  2],\n",
    "           [\"24.0_01_15\",  2],\n",
    "           [\"25.0_01_07\",  1],\n",
    "           [\"28.0_02_13\",  3],\n",
    "           [\"29.0_01_11\",  1],\n",
    "           [\"29.0_02_06\",  2],\n",
    "           [\"32.0_02_12\",  1],\n",
    "           [\"34.0_01_15\",  1],\n",
    "           [\"34.0_01_18\",  1],\n",
    "           [\"35.0_01_03\",  1],\n",
    "           [\"35.0_01_16\",  1],\n",
    "           [\"36.0_01_06\",  2],\n",
    "           [\"38.0_01_02\",  3],\n",
    "           [\"51.5_01_01\",  1],\n",
    "           [\"29.0_02_08\", -1],\n",
    "           [\"58.0_02_01\", -1],\n",
    "           [\"35.0_02_08\",  2],  \n",
    "           [\"26.0_01_19\", -1],\n",
    "           [\"64.0_01_25\", -1],\n",
    "           [\"79.0_02_15\",  1],\n",
    "           [\"66.0_01_18\", -1],\n",
    "           [\"74.0_01_08\", -1],\n",
    "           [\"68.0_01_11\", -1],\n",
    "           [\"64.0_02_14\",  1],  \n",
    "           [\"28.0_02_26\",  1],  \n",
    "           [\"55.0_02_20\",  3],  \n",
    "           [\"74.0_02_01\",  1],\n",
    "           [\"24.0_02_04\",  1], \n",
    "           [\"67.0_02_23\", -1], \n",
    "           [\"73.0_02_06\", -1], \n",
    "           [\"38.0_02_03\", -1], \n",
    "           [\"38.0_02_19\",  2], \n",
    "           [\"67.0_01_06\", -1], \n",
    "           [\"39.0_01_13\",  3], \n",
    "           [\"67.0_01_12\", -1], \n",
    "           [\"32.0_02_03\",  2],\n",
    "           [\"63.0_01_06\", -1], \n",
    "           [\"83.0_01_23\", -1],  \n",
    "           [\"87.0_02_07\", -1], \n",
    "           [\"84.0_02_23\", -1], \n",
    "           [\"75.0_02_03\",  3],  \n",
    "           [\"52.0_01_08\",  1],  \n",
    "           [\"88.0_02_12\", -1],\n",
    "           [\"70.0_01_07\",  2],\n",
    "           [\"69.0_02_19\",  1],\n",
    "           [\"49.0_02_06\",  1],\n",
    "           [\"44.0_01_19\", -1],\n",
    "           [\"56.5_02_22\", -1],\n",
    "           [\"65.0_01_01\",  2],\n",
    "           [\"71.0_01_03\", -1],\n",
    "           [\"73.0_01_14\",  2],\n",
    "           [\"32.0_02_09\",  2],\n",
    "           [\"81.0_01_08\", -1],\n",
    "           [\"32.0_01_17\", -1],\n",
    "           [\"67.0_01_04\", -1],\n",
    "           [\"73.0_02_19\",  1],\n",
    "           [\"51.0_02_02\",  1],\n",
    "           [\"43.0_01_15\",  1],\n",
    "           [\"67.0_01_05\", -1],\n",
    "           [\"26.0_01_15\", -1],\n",
    "           [\"36.0_01_08\",  1],\n",
    "           [\"45.0_02_13\", -1],\n",
    "           [\"84.0_02_19\",  2],\n",
    "           [\"61.0_02_22\",  3],  \n",
    "           [\"73.0_01_03\",  1],\n",
    "           [\"24.0_01_23\",  2],\n",
    "           [\"26.0_01_20\",  1],\n",
    "           [\"27.0_01_22\", -1],\n",
    "           [\"71.0_02_07\", -1],\n",
    "           [\"67.0_01_17\", -1],\n",
    "           [\"59.0_01_05\",  2],\n",
    "           [\"34.0_02_16\", -1],\n",
    "           [\"58.0_02_10\", -1],\n",
    "           [\"20.0_01_13\",  2],\n",
    "           [\"37.0_02_22\",  1],\n",
    "           [\"59.0_02_05\",  3],\n",
    "           [\"32.0_02_25\",  2],\n",
    "           [\"65.0_02_19\",  1],\n",
    "           [\"57.0_01_21\",  2],\n",
    "           [\"69.0_01_13\", -1],\n",
    "           [\"59.0_01_24\", -1],\n",
    "           [\"22.0_01_10\", -1],\n",
    "           [\"26.0_02_04\", -1],\n",
    "           [\"51.5_02_07\",  2],\n",
    "           [\"36.0_02_03\", -1],\n",
    "           [\"65.0_01_06\",  2],\n",
    "           [\"57.0_01_01\",  3],\n",
    "           [\"56.5_02_21\", -1],\n",
    "           [\"73.0_02_05\",  0],\n",
    "           [\"50.0_02_21\", -1],\n",
    "           [\"79.0_02_20\",  2],\n",
    "           [\"63.0_01_11\", -1], \n",
    "           [\"72.0_02_06\",  3],    \n",
    "           [\"62.0_02_14\",  3],\n",
    "           [\"23.0_01_03\",  2],\n",
    "           [\"54.0_02_15\", -1],\n",
    "           [\"65.0_02_16\",  2],\n",
    "           [\"32.0_02_06\",  1],\n",
    "           [\"53.0_01_10\",  3],\n",
    "           [\"41.0_02_13\",  2],    \n",
    "           [\"45.0_01_07\", -1],\n",
    "           [\"50.0_01_11\",  4],   \n",
    "           [\"65.0_02_17\",  1],\n",
    "           [\"80.0_02_10\",  2],\n",
    "           [\"46.0_01_01\",  1],\n",
    "           [\"85.0_01_24\", -1],\n",
    "           [\"54.0_01_11\", -1], \n",
    "           [\"71.0_01_18\",  2],\n",
    "           [\"87.0_02_17\", -1],\n",
    "           [\"66.0_02_23\",  1],\n",
    "           [\"36.0_01_01\",  2],\n",
    "           [\"38.0_02_18\",  2],  \n",
    "           [\"39.0_02_08\",  2],\n",
    "           [\"34.0_02_25\",  2],\n",
    "           [\"61.0_02_10\",  1],\n",
    "           [\"36.0_02_06\", -1],\n",
    "           [\"64.0_01_18\", -1],\n",
    "           [\"81.0_02_07\", -1],\n",
    "           [\"28.0_02_06\",  3],\n",
    "           [\"31.0_02_04\",  2],\n",
    "           [\"43.0_02_20\", -1],\n",
    "           [\"27.0_02_15\",  1],\n",
    "           [\"71.0_02_23\",  4],\n",
    "           [\"74.0_01_16\",  5],   \n",
    "           [\"31.0_02_24\",  3],   \n",
    "           [\"54.0_01_08\",  1],\n",
    "           [\"42.0_01_08\",  2],  \n",
    "\t\t   [\"33.0_02_13\",  1],\n",
    "\t\t   [\"30.0_01_24\",  4],\n",
    "\t\t   [\"52.0_01_17\", -1],\n",
    "\t\t   [\"32.0_01_25\",  1],       \n",
    "\t\t   [\"22.0_02_25\", -1],\n",
    "\t\t   [\"78.0_01_04\",  1], \n",
    "\t\t   [\"19.0_02_25\",  2],\n",
    "\t\t   [\"53.0_01_23\",  2],\n",
    "\t\t   [\"82.0_02_26\",  2],\n",
    "\t\t   [\"23.0_02_01\",  3],\n",
    "\t\t   [\"23.0_02_16\",  2],\n",
    "\t\t   [\"87.0_02_12\",  2],       \n",
    "\t\t   [\"50.0_02_04\",  2],       \n",
    "\t\t   [\"70.0_02_04\",  1],       \n",
    "\t\t   [\"43.0_01_04\", -1],\n",
    "\t\t   [\"40.0_01_06\", -1],\n",
    "\t\t   [\"51.5_01_02\", -1],\n",
    "\t\t   [\"32.0_01_06\", -1],\n",
    "\t\t   [\"70.0_01_17\", -1],\n",
    "\t\t   [\"84.0_01_21\", -1],\n",
    "\t\t   [\"36.0_02_14\", -1],\n",
    "\t\t   [\"33.0_01_06\", -1],\n",
    "\t\t   [\"31.0_01_23\", -1],\n",
    "\t\t   [\"83.0_01_11\",  1],\n",
    "\t\t   [\"87.0_01_02\",  1],\n",
    "\t\t   [\"48.0_01_13\",  2],\n",
    "\t\t   [\"80.0_01_25\", -1],\n",
    "\t\t   [\"24.0_02_09\", -1],\n",
    "\t\t   [\"57.0_01_25\", -1],\n",
    "\t\t   [\"65.0_02_18\", -1],\n",
    "\t\t   [\"85.0_01_18\", -1],\n",
    "\t\t   [\"48.0_01_20\", -1],\n",
    "\t\t   [\"61.0_02_03\", -1],\n",
    "\t\t   [\"25.0_01_09\", -1],\n",
    "\t\t   [\"29.0_02_10\", -1],\n",
    "\t\t   [\"56.0_02_05\", -1],\n",
    "\t\t   [\"61.0_01_13\", -1],\n",
    "\t\t   [\"77.0_02_20\", -1],\n",
    "\t\t   [\"81.0_01_12\", -1],\n",
    "\t\t   [\"86.0_01_01\",  1],\n",
    "\t\t   [\"78.0_01_17\",  1],\n",
    "\t\t   [\"43.0_01_11\",  1],\n",
    "\t\t   [\"60.0_01_04\",  2],\n",
    "\t\t   [\"66.0_02_11\",  1],\n",
    "\t\t   [\"76.0_02_02\",  3],\n",
    "\t\t   [\"36.0_01_07\",  2],\n",
    "\t\t   [\"30.0_01_03\",  1],\n",
    "\t\t   [\"49.0_01_05\",  1],\n",
    "\t\t   [\"58.0_02_18\",  2],\n",
    "\t\t   [\"85.0_02_14\",  2],\n",
    "\t\t   [\"22.0_02_19\",  4],\n",
    "\t\t   [\"33.0_02_11\",  5],\n",
    "\t\t   [\"53.0_01_16\",  2],\n",
    "\t\t   [\"27.0_02_06\",  3],\n",
    "\t\t   [\"51.0_01_19\",  2],\n",
    "\t\t   [\"57.0_01_13\",  2],\n",
    "\t\t   [\"59.0_01_07\",  2],\n",
    "\t\t   [\"60.0_01_18\",  2],\n",
    "\t\t   [\"69.0_01_23\",  2],\n",
    "\t\t   [\"62.0_02_26\",  1],           \n",
    "           [\"34.0_01_13\",  2]]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T21:38:15.653225Z",
     "start_time": "2020-12-09T21:38:15.637581Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# returns difference between the entire training index as C5train_index and ALL 3606 LR stimuli as c5test_index.\n",
    "#    It should be noted that c5test_index was not part of the original train/test questions 1 thru 191 above\n",
    "# import numpy as np \n",
    "c5train_index = list(np.array(c5train).transpose()[0])\n",
    "c5full_index = list(df['Order'])\n",
    "c5test_index = list(list(set(c5full_index)-set(c5train_index)) + list(set(c5train_index)-set(c5full_index)))\n",
    "# In the format...\n",
    "# ['19.0_01_07',\n",
    "#  '20.0_01_14',\n",
    "#  '20.0_02_22',..]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c5test = list(zip(c5test_index, [-1] * len(c5test_index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T21:38:37.003798Z",
     "start_time": "2020-12-09T21:38:15.686410Z"
    },
    "init_cell": true,
    "tags": [
     "Function2"
    ]
   },
   "outputs": [],
   "source": [
    "# Function to take a single  [\"PT_sec_Quest\", -1] format and returns a list of lists containing [[sents, sent],[]]\n",
    "\n",
    "def prepCon(df, pairs):                    # pairs as [ [[Sentences], ConcNumber, PT/Sec/Quest], \n",
    "    results = []                           #            [[Sent1, Sent2, Sent3], 1, \"20.0_02_05\"]  ]\n",
    "    for i in pairs:\n",
    "#                   [*df[df['Order'].str.contains(\"19.0_01_07\")].loc[106,\"docS\"                                  ].sents]      \n",
    "        sentences = [*df[df['Order'].str.contains(i[0])        ].loc[df[df['Order']==i[0]].index.values[0],\"docS\"].sents]\n",
    "        results.append([sentences,\n",
    "                        [np.asarray([0] * len(sentences), dtype=np.int64)] if i[1] == -1 else [np.bincount([i[1]], None, len(sentences))],    # Index of conclusion, expressed as binary list.  e.g. [0,0,1,0]\n",
    "                        [i[0]]])          # the PT/Sec/Quest Number Identifier.\n",
    "    return results\n",
    "\n",
    "alist = prepCon(df, c5train)\n",
    "blist = prepCon(df, c5test)\n",
    "# Curren trun time aprox 20 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REVIEW prepCon results START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T19:55:41.091713Z",
     "start_time": "2020-12-07T19:55:41.079922Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[A commonly accepted myth is that left-handed people are more prone to cause accidents than are right-handed people.,\n",
       "   But this is, in fact, just a myth, as is indicated by the fact that more household accidents are caused by right-handed people than are caused by left-handed people.],\n",
       "  [array([0, 1], dtype=int64)],\n",
       "  ['19.0_01_07']],\n",
       " [[Yolanda: Gaining access to computers without authorization and manipulating the data and programs they contain is comparable to joyriding in stolen cars; both involve breaking into private property and treating it recklessly.,\n",
       "   Joyriding, however, is the more dangerous crime because it physically endangers people, whereas only intellectual property is harmed in the case of computer crimes.  ,\n",
       "   Arjun: I disagree!,\n",
       "   For example, unauthorized use of medical records systems in hospitals could damage data systems on which human lives depend, and therefore computer crimes also cause physical harm to people.],\n",
       "  [array([0, 0, 1, 0], dtype=int64)],\n",
       "  ['20.0_01_14']],\n",
       " [[Wirth: All efforts to identify a gene responsible for predisposing people to manic-depression have failed.,\n",
       "   In fact, nearly all researchers now agree that there is no \"manic-depression gene.\",\n",
       "   Therefore, if these researchers are right, any claim that some people are genetically predisposed to manic-depression is simply false.  ,\n",
       "   Chang: I do not dispute your evidence, but I take issue with your conclusion.,\n",
       "   Many of the researchers you refer to have found evidence that a set of several genes is involved and that complex interactions among these genes produce a predisposition to manic-depression.],\n",
       "  [array([0, 0, 0, 1, 0], dtype=int64)],\n",
       "  ['20.0_02_22']]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify Train/Test Data output. While c5train, is used here, any list of list as [[\"PT_sec_quest\", Conc#], etc]\n",
    "#    may be used.  This is used to test the function \"prepCon()\"\n",
    "test_list = c5train\n",
    "# test_list = [[\"19.0_01_07\",  1],  \n",
    "#              [\"20.0_01_14\",  2]]\n",
    "compare_list = prepCon(df, test_list)\n",
    "compare_list[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REVIEW prepCon results END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Prep Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T21:38:37.029255Z",
     "start_time": "2020-12-09T21:38:37.010639Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"ner\"])\n",
    "# nlp.add_pipe(set_custom_boundaries, before=\"parser\")\n",
    "# nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T21:38:37.067497Z",
     "start_time": "2020-12-09T21:38:37.032111Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['set_custom_boundaries', 'parser', 'textcat']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the built-in textcat component to the pipeline.\n",
    "# page code edited.  \"text_cat\" to \"textcat in line #4 below\"\n",
    "textcat=nlp.create_pipe( \"textcat\", config={\"exclusive_classes\": True, \"architecture\": \"simple_cnn\"})\n",
    "nlp.add_pipe(textcat, last=True)\n",
    "\n",
    "# Adding the labels to textcat\n",
    "textcat.add_label(\"POSITIVE\")\n",
    "textcat.add_label(\"NEGATIVE\")\n",
    "\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T06:42:35.098710Z",
     "start_time": "2020-12-05T06:42:35.085021Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('textcat', <spacy.pipeline.pipes.TextCategorizer at 0x27a5b825c18>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run to remove pipe added above\n",
    "# nlp.remove_pipe('textcat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T21:38:37.103431Z",
     "start_time": "2020-12-09T21:38:37.091689Z"
    },
    "hidden": true,
    "init_cell": true,
    "run_control": {
     "marked": true
    },
    "tags": [
     "Function"
    ]
   },
   "outputs": [],
   "source": [
    "# preps a single stimuls in [(text sentence), {dict: POSITIVE, NEGATIVE}] format\n",
    "def load_stimuls(stim):      # takes alist or blist variables\n",
    "    ss, yy, ii = enumerate(stim)  # ss=sentences, yy=0/1 for yes/no stim, ii=stimulus index ID\n",
    "    l = []\n",
    "#     print(len(ss[1]))\n",
    "#     print(ss[1])\n",
    "#     t_senLengths.append(len(ss[1]))\n",
    "    for s, y in zip(ss[1], *yy[1]):\n",
    "#         print(s)\n",
    "        l.append((s.text, {'cats': {'POSITIVE': bool(y), 'NEGATIVE': not bool(y)}}))\n",
    "#         l.append((s.text, {'POSITIVE': bool(y), 'NEGATIVE': not bool(y)}))   \n",
    "#     print(\"\\n\")\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T21:38:37.118047Z",
     "start_time": "2020-12-09T21:38:37.108307Z"
    },
    "hidden": true,
    "init_cell": true,
    "run_control": {
     "marked": true
    },
    "tags": [
     "Function"
    ]
   },
   "outputs": [],
   "source": [
    "def count_sent(stim):      # takes alist or blist variables\n",
    "    ss, yy, ii = enumerate(stim)  # ss=sentences, yy=0/1 for yes/no stim, ii=stimulus index ID\n",
    "#     num_of_sent = []\n",
    "#     print(len(ss[1]))\n",
    "#     for s in ss:\n",
    "#         print(s)\n",
    "#     num_of_sent.append(len(ss[1]))\n",
    "    return len(ss[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T21:38:37.218637Z",
     "start_time": "2020-12-09T21:38:37.121970Z"
    },
    "hidden": true,
    "init_cell": true,
    "run_control": {
     "marked": true
    },
    "tags": [
     "Function"
    ]
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from functools import reduce\n",
    "import operator\n",
    "import random\n",
    "# splits training data into \"train\" and \"dev\"\n",
    "\n",
    "# This function both shuffles as well as preps \n",
    "\n",
    "def shuffle_data(l, split=0.8):   # Splits the data upon an 80/20% split.  Other values may be utilized.\n",
    "    random.shuffle(l)\n",
    "    split = int(len(l) * split)\n",
    "    \n",
    "    \n",
    "    t_senLengths = []    \n",
    "    train_text = []\n",
    "    for x in l[:split]:\n",
    "        train_text.append(load_stimuls(x))\n",
    "        t_senLengths.append(count_sent(x))\n",
    "        \n",
    "\n",
    "    d_t = []\n",
    "    d_c = []\n",
    "    d_senLengths = []\n",
    "    for stimuli in l[split:]:  \n",
    "        for areConc in stimuli[1]:\n",
    "            for isConc in areConc:\n",
    "                d_c.append({'POSITIVE': bool(isConc), 'NEGATIVE': not bool(isConc)})\n",
    "        d_senLengths.append(len(stimuli[0]))\n",
    "        for sentences in stimuli[0]:\n",
    "            d_t.append(sentences.text)\n",
    "\n",
    "\n",
    "    \n",
    "    return list(itertools.chain.from_iterable(train_text)), tuple(d_t), d_c, t_senLengths, d_senLengths\n",
    "\n",
    "train_data, dev_texts, dev_cats, train_senLengths, dev_senLengths = shuffle_data(alist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### REVIEW Formatted train/test results START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T03:28:01.703226Z",
     "start_time": "2020-11-26T03:28:01.691513Z"
    },
    "hidden": true,
    "run_control": {
     "marked": true
    },
    "scrolled": true,
    "tags": [
     "Verify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Veterinarian: A disease of purebred racehorses that is caused by a genetic defect prevents afflicted horses from racing and can cause paralysis and death.',\n",
       "  {'cats': {'POSITIVE': False, 'NEGATIVE': True}}),\n",
       " ('Some horse breeders conclude that because the disease can have such serious consequences, horses with this defect should not be bred.',\n",
       "  {'cats': {'POSITIVE': False, 'NEGATIVE': True}}),\n",
       " ('But they are wrong because, in most cases, the severity of the disease can be controlled by diet and medication, and the defect also produces horses of extreme beauty that are in great demand in the horse show industry.',\n",
       "  {'cats': {'POSITIVE': True, 'NEGATIVE': False}}),\n",
       " ('Anthropologist: Every human culture has taboos against eating certain animals.',\n",
       "  {'cats': {'POSITIVE': False, 'NEGATIVE': True}}),\n",
       " ('Some researchers have argued that such taboos originated solely for practical reasons, pointing out, for example, that in many cultures it is taboo to eat domestic animals that provide labor and that are therefore worth more alive than dead.',\n",
       "  {'cats': {'POSITIVE': False, 'NEGATIVE': True}})]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T16:40:36.024292Z",
     "start_time": "2020-11-27T16:40:36.016476Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Camera manufacturers typically advertise their products by citing the resolution of their cameras' lenses, the resolution of a lens being the degree of detail the lens is capable of reproducing in the image it projects onto the film.\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T16:40:38.624952Z",
     "start_time": "2020-11-27T16:40:38.605346Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': {'POSITIVE': False, 'NEGATIVE': True}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T03:26:19.671501Z",
     "start_time": "2020-11-26T03:26:19.658806Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T16:40:41.677822Z",
     "start_time": "2020-11-27T16:40:41.665410Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'POSITIVE': False, 'NEGATIVE': True}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][1]['cats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T16:40:44.373491Z",
     "start_time": "2020-11-27T16:40:44.364623Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Cynthia: Corporations amply fund research that generates marketable new technologies.',\n",
       " 'But the fundamental goal of science is to achieve a comprehensive knowledge of the workings of the universe.',\n",
       " 'The government should help fund those basic scientific research projects that seek to further our theoretical knowledge of nature.  ',\n",
       " 'Luis: The basic goal of government support of scientific research is to generate technological advances that will benefit society as a whole.',\n",
       " 'So only research that is expected to yield practical applications in fields such as agriculture and medicine ought to be funded.')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T03:28:11.806763Z",
     "start_time": "2020-11-26T03:28:11.797964Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dev_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T03:29:02.244741Z",
     "start_time": "2020-11-26T03:29:02.233026Z"
    },
    "hidden": true,
    "scrolled": true,
    "tags": [
     "Verify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'POSITIVE': False, 'NEGATIVE': True},\n",
       " {'POSITIVE': False, 'NEGATIVE': True},\n",
       " {'POSITIVE': False, 'NEGATIVE': True},\n",
       " {'POSITIVE': False, 'NEGATIVE': True},\n",
       " {'POSITIVE': True, 'NEGATIVE': False}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_cats[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T03:29:22.922957Z",
     "start_time": "2020-11-26T03:29:22.915138Z"
    },
    "hidden": true,
    "tags": [
     "Verify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dev_cats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### REVIEW Formatted train/test results END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Most of the inspiration for the code below came from \n",
    "#    https://www.machinelearningplus.com/nlp/custom-text-classification-spacy/\n",
    "#    Edits have been notated where appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T21:38:37.244991Z",
     "start_time": "2020-12-09T21:38:37.223520Z"
    },
    "init_cell": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(tokenizer, textcat, texts, cats):  \n",
    "    docs = (tokenizer(text) for text in texts)\n",
    "    tp = 0.0  # True positives\n",
    "    fp = 1e-8  # False positives\n",
    "    fn = 1e-8  # False negatives\n",
    "    tn = 0.0  # True negatives\n",
    "    for i, doc in enumerate(textcat.pipe(docs)):\n",
    "        gold = cats[i]\n",
    "        for label, score in doc.cats.items():\n",
    "            if label not in gold:\n",
    "                continue\n",
    "            if label == \"NEGATIVE\":\n",
    "                continue\n",
    "            if score >= 0.5 and gold[label] >= tp_lim:  # True Positive (as tp_lim) etc. were constructed as global variables.\n",
    "                tp += 1.0\n",
    "            elif score >= 0.5 and gold[label] < fp_lim:\n",
    "                fp += 1.0\n",
    "            elif score < 0.5 and gold[label] < tn_lim:\n",
    "                tn += 1\n",
    "            elif score < 0.5 and gold[label] >= fn_lim:\n",
    "                fn += 1\n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)  # accuracy added to the evaluation process.\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    \n",
    "    if (precision + recall) == 0:\n",
    "        f_score = 0.0\n",
    "    else:\n",
    "        f_score = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "\n",
    "    # the following code adds accuracy as well as TP, TN, FP, FN to the dictionary returned from this function.\n",
    "    return {\"textcat_a\": accuracy, \"textcat_p\": precision, \"textcat_r\": recall, \"textcat_f\": f_score,  \n",
    "            \"TP\": tp, \"FP\": fp, \"TN\": tn, \"FN\": fn}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### START Old evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### END Old Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T05:45:47.426995Z",
     "start_time": "2020-12-06T05:45:47.205264Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from spacy.util import minibatch, compounding, decaying\n",
    "\n",
    "# Disabling other components\n",
    "viewbatch = []   \n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']\n",
    "\n",
    "\n",
    "def run_multi_batch(num_of_cycles, n_iter):\n",
    "    print(\"Training the model...\")\n",
    "    print('{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}'.format('LOSS', 'Accuracy', 'Precision', 'Recall', 'Fscore', \"TP\", \"FP\", \"TN\", \"FN\"))    \n",
    "    for b in range(0, num_of_cycles):\n",
    "        print(\"cycle:\", b)\n",
    "        with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "            optimizer = nlp.begin_training()\n",
    "\n",
    "            # Performing training\n",
    "            for i in range(n_iter):\n",
    "                losses = {}\n",
    "                batches = minibatch(train_data, size=iter(train_senLengths))\n",
    "\n",
    "                for batch in batches:\n",
    "                    texts, annotations = zip(*batch)\n",
    "                    viewbatch.append([texts, annotations])   \n",
    "                    nlp.update(texts, annotations, sgd=optimizer, drop=next(drop_rate),      # running this line creates a decaying drop rate    \n",
    "#                     nlp.update(texts, annotations, sgd=optimizer, drop=0,                    # running this line maintains a constant drop rate\n",
    "                               losses=losses)\n",
    "\n",
    "              # Calling the evaluate() function and printing the scores\n",
    "                with textcat.model.use_params(optimizer.averages):\n",
    "                    scores = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)\n",
    "                print('{0:.3f}\\t{1:.3f}\\t\\t{2:.3f}\\t\\t{3:.3f}\\t{4:.3f}\\t{5:.0f}\\t{6:.0f}\\t{7:.0f}\\t{8:.0f}'  \n",
    "                      .format(losses['textcat'], \n",
    "                              scores['textcat_a'], scores['textcat_p'],\n",
    "                              scores['textcat_r'], scores['textcat_f'],\n",
    "                              scores['TP'], scores['FP'], scores['TN'], scores['FN']))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T06:57:00.564000Z",
     "start_time": "2020-12-06T05:45:59.942109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "LOSS \tAccuracy\tPrecision\tRecall\tFscore\t TP  \t FP  \t TN  \t FN  \n",
      "cycle: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rhaml003\\AppData\\Local\\Continuum\\anaconda3\\envs\\CAPSTONE\\lib\\site-packages\\ipykernel_launcher.py:21: DeprecationWarning: generator 'minibatch' raised StopIteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.193\t0.821\t\t0.552\t\t0.593\t0.571\t16\t13\t94\t11\n",
      "0.484\t0.858\t\t0.700\t\t0.519\t0.596\t14\t6\t101\t13\n",
      "cycle: 1\n",
      "0.383\t0.821\t\t0.560\t\t0.519\t0.538\t14\t11\t96\t13\n",
      "0.503\t0.836\t\t0.632\t\t0.444\t0.522\t12\t7\t100\t15\n",
      "cycle: 2\n",
      "0.669\t0.836\t\t0.600\t\t0.556\t0.577\t15\t10\t97\t12\n",
      "0.762\t0.806\t\t0.520\t\t0.481\t0.500\t13\t12\t95\t14\n",
      "cycle: 3\n",
      "0.549\t0.799\t\t0.500\t\t0.481\t0.491\t13\t13\t94\t14\n",
      "0.040\t0.821\t\t0.556\t\t0.556\t0.556\t15\t12\t95\t12\n",
      "cycle: 4\n",
      "0.344\t0.843\t\t0.600\t\t0.667\t0.632\t18\t12\t95\t9\n",
      "0.535\t0.843\t\t0.625\t\t0.556\t0.588\t15\t9\t98\t12\n"
     ]
    }
   ],
   "source": [
    "# Collects most variables \n",
    "# from spacy.util import decaying\n",
    "drop_rate = decaying(0.25, 0.15, len(train_data))  # constructs a decay function https://spacy.io/usage/training#tips-dropout\n",
    "tp_lim = 0.5\n",
    "fp_lim = 0.5\n",
    "tn_lim = 0.5\n",
    "fn_lim = 0.5\n",
    "n_iter = 2   # increasing this value does not increase the number of RANDOMIZED iterations, but runs an entire epoch\n",
    "num_of_cycles = 5  # this value WILL both run extra epochs as well as RANDOMIZE them.\n",
    "\n",
    "run_multi_batch(num_of_cycles, n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T06:57:04.587944Z",
     "start_time": "2020-12-06T06:57:04.326691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to ./YourSaveFolder\n"
     ]
    }
   ],
   "source": [
    "# Saves trained pipe to disk\n",
    "output_dir=\"./YourSaveFolder\"\n",
    "nlp.to_disk(output_dir)\n",
    "print(\"Saved model to\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T05:07:54.840864Z",
     "start_time": "2020-12-05T05:07:54.606492Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'textcat_a': 0.8208955222655379,\n",
       " 'textcat_p': 0.5555555553497942,\n",
       " 'textcat_r': 0.5555555553497942,\n",
       " 'textcat_f': 0.5555555553497942,\n",
       " 'TP': 15.0,\n",
       " 'FP': 12.00000001,\n",
       " 'TN': 95.0,\n",
       " 'FN': 12.00000001}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_scores = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)\n",
    "save_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T20:14:59.373428Z",
     "start_time": "2020-11-29T20:14:59.362660Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Veterinarian: A disease of purebred racehorses that is caused by a genetic defect prevents afflicted horses from racing and can cause paralysis and death.',\n",
       "   'Some horse breeders conclude that because the disease can have such serious consequences, horses with this defect should not be bred.',\n",
       "   'But they are wrong because, in most cases, the severity of the disease can be controlled by diet and medication, and the defect also produces horses of extreme beauty that are in great demand in the horse show industry.'),\n",
       "  ({'cats': {'POSITIVE': False, 'NEGATIVE': True}},\n",
       "   {'cats': {'POSITIVE': False, 'NEGATIVE': True}},\n",
       "   {'cats': {'POSITIVE': True, 'NEGATIVE': False}})],\n",
       " [('Anthropologist: Every human culture has taboos against eating certain animals.',\n",
       "   'Some researchers have argued that such taboos originated solely for practical reasons, pointing out, for example, that in many cultures it is taboo to eat domestic animals that provide labor and that are therefore worth more alive than dead.',\n",
       "   'But that conclusion is unwarranted; taboos against eating certain animals might instead have arisen for symbolic, ritualistic reasons, and the presence of the taboos might then have led people to find other uses for those animals.'),\n",
       "  ({'cats': {'POSITIVE': False, 'NEGATIVE': True}},\n",
       "   {'cats': {'POSITIVE': False, 'NEGATIVE': True}},\n",
       "   {'cats': {'POSITIVE': True, 'NEGATIVE': False}})],\n",
       " [('Generations of European-history students have been taught that a political assassination caused the First World War.',\n",
       "   'Without some qualification, however, this teaching is bound to mislead, since the war would not have happened without the treaties and alliances that were already in effect and the military force that was already amassed.',\n",
       "   'These were the deeper causes of the war, whereas the assassination was a cause only in a trivial sense.',\n",
       "   'It was like the individual spark that happens to ignite a conflagration that was, in the prevailing conditions, inevitable.'),\n",
       "  ({'cats': {'POSITIVE': False, 'NEGATIVE': True}},\n",
       "   {'cats': {'POSITIVE': True, 'NEGATIVE': False}},\n",
       "   {'cats': {'POSITIVE': False, 'NEGATIVE': True}},\n",
       "   {'cats': {'POSITIVE': False, 'NEGATIVE': True}})]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewbatch[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T17:26:57.585230Z",
     "start_time": "2020-11-25T17:26:57.576435Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "# https://stackoverflow.com/questions/56804988/change-default-learning-rate-in-spacys-optimizer\n",
    "# https://spacy.io/api/cli#train-hyperparams\n",
    "# https://github.com/explosion/spaCy/blob/69e70ffae16700e990d60640f27eb7f980c0ba50/spacy/_ml.py#L49\n",
    "\n",
    "# Stats\n",
    "# https://towardsdatascience.com/a-complete-understanding-of-precision-recall-and-f-score-concepts-23dc44defef6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep for output and Human readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T21:38:37.305551Z",
     "start_time": "2020-12-09T21:38:37.279187Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "## Function to control floating point digits displayed.\n",
    "# http://randlet.com/blog/python-significant-figures-format/\n",
    "import math\n",
    "\n",
    "def to_precision(x,p):\n",
    "    \"\"\"\n",
    "    returns a string representation of x formatted with a precision of p\n",
    "\n",
    "    Based on the webkit javascript implementation taken from here:\n",
    "    https://code.google.com/p/webkit-mirror/source/browse/JavaScriptCore/kjs/number_object.cpp\n",
    "    \"\"\"\n",
    "\n",
    "    x = float(x)\n",
    "\n",
    "    if x == 0.:\n",
    "        return \"0.\" + \"0\"*(p-1)\n",
    "\n",
    "    out = []\n",
    "\n",
    "    if x < 0:\n",
    "        out.append(\"-\")\n",
    "        x = -x\n",
    "\n",
    "    e = int(math.log10(x))\n",
    "    tens = math.pow(10, e - p + 1)\n",
    "    n = math.floor(x/tens)\n",
    "\n",
    "    if n < math.pow(10, p - 1):\n",
    "        e = e -1\n",
    "        tens = math.pow(10, e - p+1)\n",
    "        n = math.floor(x / tens)\n",
    "\n",
    "    if abs((n + 1.) * tens - x) <= abs(n * tens -x):\n",
    "        n = n + 1\n",
    "\n",
    "    if n >= math.pow(10,p):\n",
    "        n = n / 10.\n",
    "        e = e + 1\n",
    "\n",
    "    m = \"%.*g\" % (p, n)\n",
    "\n",
    "    if e < -2 or e >= p:\n",
    "        out.append(m[0])\n",
    "        if p > 1:\n",
    "            out.append(\".\")\n",
    "            out.extend(m[1:p])\n",
    "        out.append('e')\n",
    "        if e > 0:\n",
    "            out.append(\"+\")\n",
    "        out.append(str(e))\n",
    "    elif e == (p -1):\n",
    "        out.append(m)\n",
    "    elif e >= 0:\n",
    "        out.append(m[:e+1])\n",
    "        if e+1 < len(m):\n",
    "            out.append(\".\")\n",
    "            out.extend(m[e+1:])\n",
    "    else:\n",
    "        out.append(\"0.\")\n",
    "        out.extend([\"0\"]*-(e+1))\n",
    "        out.append(m)\n",
    "\n",
    "    return \"\".join(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output results of training against remaining stimuli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T04:51:46.356173Z",
     "start_time": "2020-12-06T04:49:21.267790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.output_area pre {white-space: pre;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['34.0_01_08']\n",
      "Conservationist: The risk to airplane passengers from collisions between airplanes using the airport and birds from the wildlife refuge is negligible. \n",
      "1.74e-3 \t Conservationist: The risk to airplane passengers from collisions between airplanes using the airport and birds from the wildlife refuge is negligible. \n",
      "In the 10 years since the refuge was established, only 20 planes have been damaged in collisions with birds, and no passenger has been injured as a result of such a collision. \n",
      "7.58e-5 \t In the 10 years since the refuge was established, only 20 planes have been damaged in collisions with birds, and no passenger has been injured as a result of such a collision. \n",
      "The wildlife refuge therefore poses no safety risk.  \n",
      "9.79e-8 \t The wildlife refuge therefore poses no safety risk.  \n",
      "Pilot: You neglect to mention that 17 of those 20 collisions occurred within the past 2 years, and that the number of birds in the refuge is rapidly increasing. \n",
      "0.977 \t Pilot: You neglect to mention that 17 of those 20 collisions occurred within the past 2 years, and that the number of birds in the refuge is rapidly increasing. \n",
      "As the number of collisions between birds and airplanes increases, so does the likelihood that at least one such collision will result in passenger injuries.\n",
      "0.284 \t As the number of collisions between birds and airplanes increases, so does the likelihood that at least one such collision will result in passenger injuries.\n",
      "\n",
      "\n",
      "['23.0_02_21']\n",
      "Helen: It was wrong of my brother Mark to tell our mother that the reason he had missed her birthday party the evening before was that he had been in a traffic accident and that by the time he was released from the hospital emergency room the party was long over. \n",
      "7.08e-4 \t Helen: It was wrong of my brother Mark to tell our mother that the reason he had missed her birthday party the evening before was that he had been in a traffic accident and that by the time he was released from the hospital emergency room the party was long over. \n",
      "Saying something that is false can never be other than morally wrong, and there had been no such accidentÃ¢â‚¬â€Mark had simply forgotten all about the party.\n",
      "2.97e-4 \t Saying something that is false can never be other than morally wrong, and there had been no such accidentÃ¢â‚¬â€Mark had simply forgotten all about the party.\n",
      "\n",
      "\n",
      "['83.0_01_16']\n",
      "Fremont: Simpson is not a viable candidate for chief executive of Pod Oil because he has no background in the oil industry.  \n",
      "3.03e-3 \t Fremont: Simpson is not a viable candidate for chief executive of Pod Oil because he has no background in the oil industry.  \n",
      "Galindo: I disagree. \n",
      "1.00 \t Galindo: I disagree. \n",
      "An oil industry background is no guarantee of success. \n",
      "2.80e-4 \t An oil industry background is no guarantee of success. \n",
      "Look no further than Pod Oil's last chief executive, who had decades of oil industry experience but steered the company to the brink of bankruptcy.\n",
      "4.68e-3 \t Look no further than Pod Oil's last chief executive, who had decades of oil industry experience but steered the company to the brink of bankruptcy.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_area pre {white-space: pre;}</style>\"))\n",
    "\n",
    "def search_blist(l):  \n",
    "    for row in l:\n",
    "        print(row[2], end=\"\\n\")\n",
    "        for sentences in row[0]:\n",
    "            d = nlp(sentences.as_doc().text)\n",
    "            print(d)\n",
    "            print(to_precision(d.cats['POSITIVE'], 3), '\\t', d)\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "results = search_blist(blist[:3])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Used to verify training data is sent correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T20:54:09.481673Z",
     "start_time": "2020-11-29T20:54:08.109599Z"
    },
    "hidden": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.0_01_07\n",
      "0 A commonly accepted myth is that left-handed people are more prone to cause accidents than are right-handed people.\n",
      "1 But this is, in fact, just a myth, as is indicated by the fact that more household accidents are caused by right-handed people than are caused by left-handed people.\n",
      "\n",
      "\n",
      "20.0_01_14\n",
      "0 Yolanda: Gaining access to computers without authorization and manipulating the data and programs they contain is comparable to joyriding in stolen cars; both involve breaking into private property and treating it recklessly.\n",
      "0 Joyriding, however, is the more dangerous crime because it physically endangers people, whereas only intellectual property is harmed in the case of computer crimes.  \n",
      "1 Arjun: I disagree!\n",
      "0 For example, unauthorized use of medical records systems in hospitals could damage data systems on which human lives depend, and therefore computer crimes also cause physical harm to people.\n",
      "\n",
      "\n",
      "20.0_02_22\n",
      "0 Wirth: All efforts to identify a gene responsible for predisposing people to manic-depression have failed.\n",
      "0 In fact, nearly all researchers now agree that there is no \"manic-depression gene.\"\n",
      "0 Therefore, if these researchers are right, any claim that some people are genetically predisposed to manic-depression is simply false.  \n",
      "1 Chang: I do not dispute your evidence, but I take issue with your conclusion.\n",
      "0 Many of the researchers you refer to have found evidence that a set of several genes is involved and that complex interactions among these genes produce a predisposition to manic-depression.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_pairs = [[\"19.0_01_07\",  1], \n",
    "                [\"20.0_01_14\",  2],  \n",
    "                [\"20.0_02_22\",  3]]\n",
    "\n",
    "def output_stimuli(df, output_pairs):                    \n",
    "    results = []                           \n",
    "    for i in output_pairs:\n",
    "        print(i[0], end=\"\\n\")\n",
    "#                   [*df[df['Order'].str.contains(\"19.0_01_07\")].loc[106,                                 \"docS\" ].sents]      \n",
    "        sentences = [*df[df['Order'].str.contains(i[0])        ].loc[df[df['Order']==i[0]].index.values[0],\"docS\"].sents]\n",
    "        for j, s in enumerate(sentences):         # i = index, s = sentence\n",
    "            [print(\"1\", sentences[j], end=\"\\n\") if j == i[1] else print(\"0\", sentences[j], end=\"\\n\")]\n",
    "        print(\"\\n\")\n",
    "    \n",
    "output_stimuli(df, output_pairs)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "717px",
    "left": "979.95px",
    "right": "20px",
    "top": "74.9875px",
    "width": "552.438px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
